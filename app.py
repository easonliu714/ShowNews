# -*- coding: utf-8 -*-
import asyncio
import aiohttp
import random
import time
import json
import os
import re
import schedule
import argparse
import urllib3
from datetime import datetime
from urllib.parse import urljoin
from pathlib import Path
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from bs4 import BeautifulSoup
import telegram
from telegram.constants import ParseMode

# =========================
# è¨­å®šå€
# =========================
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

USER_AGENTS = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 13_5_1) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.5 Safari/605.1.15',
]

REQUEST_PARAMS = {'timeout': 20, 'allow_redirects': True}

# å¾ç’°å¢ƒè®Šæ•¸è®€å–é…ç½®
TOKEN = os.getenv('TG_BOT_TOKEN')
CHAT_ID = os.getenv('TG_CHAT_ID')

# æª”æ¡ˆè·¯å¾‘
DATA_DIR = Path('data')
DATA_DIR.mkdir(exist_ok=True)

LOG_FILE = DATA_DIR / 'Show_News_log.json'
RUN_LOG = DATA_DIR / 'run.log'
FAILED_LOG = DATA_DIR / 'failed_messages.json'
STATS_LOG = DATA_DIR / 'connection_stats.json'

bot = None

# =========================
# å¹³å°ä¸Šä¸‹æ–‡
# =========================
class FetchContext:
    def __init__(self):
        self.ua = None
        self.cookies = {}
        self.last_referer = None
        self.consec_auth_fail = 0
        self.warmed = False

platform_contexts = {
    platform: FetchContext()
    for platform in ["æ‹“å…ƒå”®ç¥¨", "KKTIX", "OPENTIX", "å¯¬å®", "å¹´ä»£å”®ç¥¨", "UDNå”®ç¥¨ç¶²", "iBonå”®ç¥¨", "Event Go"]
}

# =========================
# Sessionè¨­å®š
# =========================
def create_session():
    session = requests.Session()
    retry = Retry(total=2, read=2, connect=2, backoff_factor=0.6, 
                  status_forcelist=(429, 500, 502, 503, 504, 403, 401))
    adapter = HTTPAdapter(max_retries=retry)
    session.mount('http://', adapter)
    session.mount('https://', adapter)
    session.headers.update({
        'User-Agent': random.choice(USER_AGENTS),
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'zh-TW,zh;q=0.9,en-US;q=0.6',
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
        'Cache-Control': 'no-cache',
        'DNT': '1',
        'Pragma': 'no-cache',
        'Sec-Fetch-Dest': 'document',
        'Sec-Fetch-Mode': 'navigate',
        'Sec-Fetch-Site': 'none'
    })
    session.verify = True
    return session

session = create_session()

# =========================
# çµ±è¨ˆèˆ‡æ—¥èªŒ
# =========================
def load_json_file(file_path):
    if not os.path.exists(file_path):
        return {}
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except (json.JSONDecodeError, FileNotFoundError):
        return {}

def save_json_file(data, file_path):
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

load_connection_stats = lambda: load_json_file(STATS_LOG)
save_connection_stats = lambda stats: save_json_file(stats, STATS_LOG)
load_log = lambda: load_json_file(LOG_FILE)
save_log = lambda log: save_json_file(log, LOG_FILE)
load_failed_log = lambda: load_json_file(FAILED_LOG)
save_failed_log = lambda log: save_json_file(log, FAILED_LOG)

def append_log_run(msg):
    log_path = Path(RUN_LOG)
    mode = 'a' if log_path.exists() else 'w'
    with log_path.open(mode, encoding='utf-8') as f:
        f.write(f"[{datetime.now()}] {msg}\n")
    print(f"[DEBUG] {msg}")

# =========================
# è¼”åŠ©å‡½å¼
# =========================
def safe_get_text(element, default="è©³å…§æ–‡"):
    return element.get_text(strip=True) if element and hasattr(element, 'get_text') and element.get_text(strip=True) else default

def get_event_category_from_title(title):
    if not title:
        return "å…¶ä»–"
    
    title_lower = title.lower()
    category_mapping = {
        "éŸ³æ¨‚æœƒ/æ¼”å”±æœƒ": ["éŸ³æ¨‚æœƒ", "æ¼”å”±æœƒ", "ç¨å¥æœƒ", "åˆå”±", "äº¤éŸ¿", "ç®¡æ¨‚", "åœ‹æ¨‚", "å¼¦æ¨‚", "é‹¼ç´", "æç´", "å·¡æ¼”", "fan concert", "fancon", "éŸ³æ¨‚ç¯€", "çˆµå£«", "æ¼”å¥", "æ­Œæ‰‹", "æ¨‚åœ˜", "tour", "live", "concert", "solo", "recital", "é›»éŸ³æ´¾å°", "è—äººè¦‹é¢æœƒ"],
        "éŸ³æ¨‚åŠ‡/æ­ŒåŠ‡": ["éŸ³æ¨‚åŠ‡", "æ­ŒåŠ‡", "musical", "opera"],
        "æˆ²åŠ‡è¡¨æ¼”": ["æˆ²åŠ‡", "èˆå°åŠ‡", "åŠ‡åœ˜", "åŠ‡å ´", "å–œåŠ‡", "å…¬æ¼”", "æŒä¸­æˆ²", "æ­Œä»”æˆ²", "è±«åŠ‡", "è©±åŠ‡", "ç›¸è²", "å¸ƒè¢‹æˆ²", "äº¬åŠ‡", "å´‘åŠ‡", "è—æ–‡æ´»å‹•"],
        "èˆè¹ˆè¡¨æ¼”": ["èˆè¹ˆ", "èˆä½œ", "èˆåœ˜", "èŠ­è•¾", "èˆåŠ‡", "ç¾ä»£èˆ", "æ°‘æ—èˆ", "è¸¢è¸èˆ"],
        "å±•è¦½/åšè¦½": ["å±•è¦½", "ç‰¹å±•", "åšç‰©é¤¨", "ç¾è¡“é¤¨", "è—è¡“å±•", "ç•«å±•", "æ”å½±å±•", "æ–‡ç‰©å±•", "ç§‘å­¸å±•", "åšè¦½æœƒ", "å‹•æ¼«"],
        "è¦ªå­æ´»å‹•": ["è¦ªå­", "å…’ç«¥", "å¯¶å¯¶", "å®¶åº­", "å°æœ‹å‹", "ç«¥è©±", "å¡é€š", "å‹•ç•«"],
        "é›»å½±æ”¾æ˜ ": ["é›»å½±", "å½±å±•", "æ•¸ä½ä¿®å¾©", "æ”¾æ˜ ", "é¦–æ˜ ", "ç´€éŒ„ç‰‡", "å‹•ç•«é›»å½±"],
        "é«”è‚²è³½äº‹": ["æ£’çƒ", "ç±ƒçƒ", "éŒ¦æ¨™è³½", "é‹å‹•æœƒ", "è¶³çƒ", "ç¾½çƒ", "ç¶²çƒ", "é¦¬æ‹‰æ¾", "è·¯è·‘", "æ¸¸æ³³", "é«”æ“", "championship", "éŠæˆ²ç«¶è³½"],
        "è¬›åº§/å·¥ä½œåŠ": ["å·¥ä½œåŠ", "èª²ç¨‹", "å°è®€", "æ²™é¾", "è¬›åº§", "é«”é©—", "ç ”ç¿’", "åŸ¹è¨“", "è«–å£‡", "ç ”è¨æœƒ", "åº§è«‡", "workshop", "è·å ´å·¥ä½œè¡“", "è³‡è¨Šç§‘æŠ€"],
        "å¨›æ¨‚è¡¨æ¼”": ["è„«å£ç§€", "é­”è¡“", "é›œæŠ€", "é¦¬æˆ²", "ç‰¹æŠ€", "é­”å¹»", "ç¶œè—", "å¨›æ¨‚", "ç§€å ´", "è¡¨æ¼”ç§€", "ç¤¾ç¾¤æ´»å‹•"],
        "å…¶ä»–": ["æ—…éŠ", "ç¾é£Ÿ", "å…¬ç›Š"]
    }
    
    for category, keywords in category_mapping.items():
        if any(keyword in title_lower for keyword in keywords):
            return category
    return "å…¶ä»–"

# =========================
# çˆ¬å–ç›¸é—œå‡½å¼
# =========================
DETAIL_URL_WHITELIST = {
    "æ‹“å…ƒå”®ç¥¨": re.compile(r"^https?://(www\.)?tixcraft\.com/activity/detail/[A-Za-z0-9_-]+", re.I),
    "KKTIX": re.compile(r"^https?://[a-z0-9-]+\.kktix\.cc/events/[A-Za-z0-9-_]+", re.I),
    "OPENTIX": re.compile(r"^https?://(www\.)?opentix\.life/event/\d+", re.I),
    "å¹´ä»£å”®ç¥¨": re.compile(r"^https?://(www\.)?ticket\.com\.tw/application/UTK02/UTK0201_\.aspx\?PRODUCT_ID=[A-Z0-9]+", re.I),
    "UDNå”®ç¥¨ç¶²": re.compile(r"^https?://(www\.)?tickets\.udnfunlife\.com/application/UTK02/UTK0201_\.aspx\?PRODUCT_ID=[A-Z0-9]+", re.I),
    "iBonå”®ç¥¨": re.compile(r"^https?://(www\.)?ticket\.ibon\.com\.tw/", re.I),
    "å¯¬å®": re.compile(r"^https?://(www\.)?kham\.com\.tw/application/UTK02/UTK0201_\.aspx\?PRODUCT_ID=[A-Z0-9]+", re.I),
    "Event Go": re.compile(r"^https?://eventgo\.bnextmedia\.com\.tw/event/detail[^\s]*$", re.I),
}

def filter_links_for_platform(links, base_url, platform_name):
    events, seen_urls = [], set()
    wl = DETAIL_URL_WHITELIST.get(platform_name)
    
    for link in links:
        href = link.get('href', '')
        title = safe_get_text(link)
        
        if not href or not title or len(title) < 3:
            continue
            
        full_url = urljoin(base_url, href)
        
        # Event Go å°ˆé–€éæ¿¾ï¼šåªæ¥å— /event/detail çš„æ´»å‹•è©³é 
        if platform_name == "Event Go":
            if not full_url.startswith("https://eventgo.bnextmedia.com.tw/event/detail"):
                continue
        
        if full_url in seen_urls or (wl and not wl.match(full_url)):
            continue
            
        if platform_name == "UDNå”®ç¥¨ç¶²":
            title = re.sub(r'\.\.\.moreNT\$\s*[\d,]+\s*~\s*[\d,]+$', '', title).strip()
            title = re.sub(r'&amp;[a-zA-Z0-9#]+;', '', title).strip()
            
        if title.lower() in ['more', 'æ›´å¤š', 'è©³æƒ…', 'è³¼ç¥¨']:
            continue
            
        events.append({
            'title': title.strip(),
            'url': full_url,
            'platform': platform_name,
            'type': get_event_category_from_title(title)
        })
        seen_urls.add(full_url)
    
    append_log_run(f"{platform_name} éæ¿¾å¾Œå‰©é¤˜ {len(events)} å€‹æœ‰æ•ˆé€£çµ")
    return events

async def fetch_text(session: aiohttp.ClientSession, url: str, timeout_sec=15):
    headers = {
        'User-Agent': random.choice(USER_AGENTS),
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'zh-TW,zh;q=0.9,en-US;q=0.8,en;q=0.7',
        'Referer': 'https://www.google.com/',
        'DNT': '1',
        'Upgrade-Insecure-Requests': '1'
    }
    
    async with session.get(url, headers=headers, allow_redirects=True, ssl=False, timeout=timeout_sec) as resp:
        if resp.status != 200:
            raise Exception(f"HTTP {resp.status}")
        text = await resp.text()
        if len(text) < 500:
            raise Exception("å…§å®¹éçŸ­ï¼Œå¯èƒ½è¢«å°é–")
        return text

# =========================
# Telegramç™¼é€
# =========================
def escape_markdown_v2(text: str) -> str:
    if not isinstance(text, str):
        text = str(text)
    escape_chars = r'_*[]()~`>#+=|{}.!-'
    return re.sub(f'([{re.escape(escape_chars)}])', r'\\\1', text)

async def send_telegram_message_with_retry(event, is_init=False, downgraded=False, max_retries=1):
    for attempt in range(max_retries):
        try:
            header = "ğŸ”„ é¦–è¼ªæ¸¬è©¦æ´»å‹•" if is_init else "ğŸ†• æ–°å¢æ´»å‹•é€šçŸ¥"
            title = escape_markdown_v2(event.get('title', 'è©³å…§æ–‡'))
            event_type = escape_markdown_v2(event.get('type', 'è©³å…§æ–‡'))
            event_date = escape_markdown_v2(event.get('date', 'è©³å…§æ–‡'))
            event_location = escape_markdown_v2(event.get('location', 'è©³å…§æ–‡'))
            event_platform = escape_markdown_v2(event.get('platform', 'è©³å…§æ–‡'))
            
            lines = [
                header,
                f"ğŸ« {title}",
                f"ğŸ“ é¡å‹ï¼š{event_type}",
                f"ğŸ“… æ—¥æœŸï¼š{event_date}",
                f"ğŸ—º åœ°é»ï¼š{event_location}",
                f"ğŸ§¾ å¹³å°ï¼š{event_platform}"
            ]
            
            if downgraded:
                lines.append("âš ï¸ è©³é è³‡è¨Šå—é™ï¼Œè«‹é»æ“Šé€£çµæŸ¥çœ‹")
            
            lines.append(f"\nğŸ“Œ [é»æˆ‘æŸ¥çœ‹è©³æƒ…]({event.get('url', '')})")
            
            msg = "\n".join(lines)
            
            if len(msg) > 4096:
                append_log_run(f"è¨Šæ¯ä»éé•·ï¼Œå¼·åˆ¶æˆªæ–·: {event.get('title')}")
                msg = "\n".join(lines[:6]) + f"\n\nğŸ“Œ [é»æˆ‘æŸ¥çœ‹è©³æƒ…]({event.get('url', '')})"
            
            await bot.send_message(chat_id=CHAT_ID, text=msg, parse_mode=ParseMode.MARKDOWN_V2)
            return True, None
            
        except Exception as err:
            error_msg = str(err)
            append_log_run(f"ç™¼é€å¤±æ•— (ç¬¬{attempt+1}æ¬¡)ï¼š{event.get('title','(ç„¡æ¨™é¡Œ)')} => {error_msg}")
            
            if "message is too long" in error_msg.lower():
                return False, "Message is too long"
                
            if attempt < max_retries - 1:
                wait_time = 5
                if "Flood control" in error_msg:
                    wait_time = min(60 * (attempt + 1), 300)
                elif any(k in error_msg.lower() for k in ['timeout', 'connect', 'network']):
                    wait_time = 15 * (attempt + 1)
                await asyncio.sleep(wait_time)
    
    return False, str(err)

# =========================
# ç°¡åŒ–çš„æª¢æŸ¥å‡½å¼
# =========================
async def simple_check():
    """ç°¡åŒ–çš„æª¢æŸ¥å‡½å¼ï¼ŒåªæŠ“å–KKTIXå’Œæ‹“å…ƒå”®ç¥¨"""
    append_log_run("é–‹å§‹åŸ·è¡Œç°¡åŒ–æ´»å‹•æª¢æŸ¥")
    
    connector = aiohttp.TCPConnector(ssl=False, limit=10, family=0)
    async with aiohttp.ClientSession(connector=connector) as aio_sess:
        try:
            # ç°¡åŒ–ç‰ˆï¼šåªæŠ“å–KKTIX
            html = await fetch_text(aio_sess, "https://kktix.com/")
            soup = BeautifulSoup(html, "html.parser")
            links = soup.select('a[href*="/events/"]')
            events = filter_links_for_platform(links, "https://kktix.com/", "KKTIX")
            
            append_log_run(f"ç™¼ç¾ {len(events)} å€‹KKTIXæ´»å‹•")
            
            # ç°¡å–®è™•ç†ï¼šåªç™¼é€å‰3å€‹æ–°æ´»å‹•
            log_data = load_log()
            new_events = [e for e in events[:3] if e['url'] not in log_data]
            
            sent_count = 0
            for event in new_events:
                success, error = await send_telegram_message_with_retry(event)
                if success:
                    sent_count += 1
                    log_data[event['url']] = {'title': event['title']}
                    save_log(log_data)
                await asyncio.sleep(2)  # é¿å…ç™¼é€å¤ªå¿«
            
            append_log_run(f"è™•ç†å®Œæˆï¼šç™¼é€ {sent_count} ç­†æ–°æ´»å‹•")
            
        except Exception as e:
            append_log_run(f"æª¢æŸ¥éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")

# =========================
# å®šæ™‚ä»»å‹™
# =========================
async def run_schedule():
    """ç•°æ­¥é‹è¡Œå®šæ™‚ä»»å‹™"""
    while True:
        schedule.run_pending()
        await asyncio.sleep(60)  # æ¯åˆ†é˜æª¢æŸ¥ä¸€æ¬¡

def setup_schedule():
    """è¨­å®šå®šæ™‚ä»»å‹™"""
    schedule.every().day.at("09:00").do(lambda: asyncio.create_task(simple_check()))
    schedule.every().day.at("15:00").do(lambda: asyncio.create_task(simple_check()))
    schedule.every().day.at("21:00").do(lambda: asyncio.create_task(simple_check()))
    append_log_run("å·²è¨­å®šæ¯æ—¥ 09:00, 15:00, 21:00 è‡ªå‹•æª¢æŸ¥")

# =========================
# ä¸»ç¨‹å¼
# =========================
async def main():
    global bot
    
    if not TOKEN or not CHAT_ID:
        append_log_run("è«‹è¨­å®šç’°å¢ƒè®Šæ•¸ TG_BOT_TOKEN èˆ‡ TG_CHAT_ID")
        return
    
    bot = telegram.Bot(token=TOKEN)
    append_log_run("ShowNews æ´»å‹•çˆ¬èŸ²å•Ÿå‹•")
    
    # è¨­å®šå®šæ™‚ä»»å‹™
    setup_schedule()
    
    # åŸ·è¡Œä¸€æ¬¡æª¢æŸ¥
    await simple_check()
    
    # åœ¨Renderä¸ŠæœƒæŒçºŒé‹è¡Œ
    if os.getenv('RENDER'):
        append_log_run("åœ¨Renderç’°å¢ƒä¸­é‹è¡Œï¼Œé–‹å§‹å®šæ™‚ä»»å‹™")
        await run_schedule()
    else:
        append_log_run("æœ¬åœ°æ¸¬è©¦å®Œæˆ")

if __name__ == "__main__":
    asyncio.run(main())
